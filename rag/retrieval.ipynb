{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Relevant Portions of Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Protocol Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the text from reader\n",
    "page_content_lookup = [page.extract_text() for page in reader.pages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class OutlineSegment:\n",
    "    title: str\n",
    "    start_page: int\n",
    "    end_page: int\n",
    "    content: str = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment - Get PDF Outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import typing\n",
    "from pypdf.generic import Destination\n",
    "\n",
    "\n",
    "def segment_outline(\n",
    "    outlines: \"list[typing.Union[Destination, list]]\", reader: PdfReader\n",
    ") -> \"list[OutlineSegment]\":\n",
    "    \"\"\"Given a list of pypdf.Destinations and a reader, segment document by outline with start and end pages\"\"\"\n",
    "\n",
    "    def _segment_destination(dest: \"Destination\") -> \"OutlineSegment\":\n",
    "        return OutlineSegment(dest.title, reader._get_page_number_by_indirect(dest.page), -1)\n",
    "\n",
    "    segments = []\n",
    "    switch_case = {\n",
    "        Destination: lambda x: [_segment_destination(x)],\n",
    "        list: lambda x: segment_outline(x, reader),\n",
    "    }\n",
    "\n",
    "    # handle first segment\n",
    "    outline_entry = outlines[0]\n",
    "    segments += switch_case[type(outline_entry)](outline_entry)\n",
    "\n",
    "    for outline_entry in outlines[1:]:\n",
    "        sub_segment = switch_case[type(outline_entry)](outline_entry)\n",
    "        segments[-1].end_page = sub_segment[-1].start_page + 1\n",
    "        segments += switch_case[type(outline_entry)](outline_entry)\n",
    "\n",
    "    return segments\n",
    "\n",
    "segments = segment_outline(reader.outline, reader)\n",
    "for segment in segments:\n",
    "    segment_pages = page_content_lookup[segment.start_page-1:segment.end_page-1]\n",
    "    segment.content = \"\\n\\n\\n\".join(segment_pages)\n",
    "\n",
    "title_segment_lookup: \"dict[str, OutlineSegment]\" = {\n",
    "    s.title: s for s in segments\n",
    "}\n",
    "len(title_segment_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment - Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/btor/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 930 sentences in this document'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "pdf_sentences = sent_tokenize(\"\\n\".join(page_content_lookup))\n",
    "pdf_sentences = [\n",
    "    s.replace('\\n', '') for s in pdf_sentences if len(s.split(\" \")) > 5\n",
    "]  # ignore sentences that are too short, likely don't contain descriptive information\n",
    "f\"There are {len(pdf_sentences)} sentences in this document\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment - Font Size (invalid)\n",
    "\n",
    "Segmenting based off of differences in font doesn't work for a few reasons:\n",
    "* across ICFs, larger font sizes don't always indicate a new segment\n",
    "* font sizes are based off of the font text matrix, which is not consistent between PDFs\n",
    "* bold and italicized elements don't consistently indicate new sections\n",
    "* numbered sections (i.e. 1. Introduction) capture the number and the title in distinct PDF elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nparts = []\\npage = reader.pages[12]\\ndef visitor_body(text, cm, tm, font_dict, font_size):\\n    y = cm[5]\\n    print(text.strip()[:50], \"|\", y, tm, font_size, font_dict)\\n    if 50 < y < 720:\\n        parts.append(text)\\n\\ntext = page.extract_text(visitor_text=visitor_body)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not worth it, skip\n",
    "\"\"\"\n",
    "parts = []\n",
    "page = reader.pages[12]\n",
    "def visitor_body(text, cm, tm, font_dict, font_size):\n",
    "    y = cm[5]\n",
    "    print(text.strip()[:50], \"|\", y, tm, font_size, font_dict)\n",
    "    if 50 < y < 720:\n",
    "        parts.append(text)\n",
    "\n",
    "text = page.extract_text(visitor_text=visitor_body)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval - Study Title\n",
    "\n",
    "It would be good to know the study title. We guess what it is based on the first 3 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abbreviated Title: AMP-224 SBRT Met Colorectal Ca   \\nVersion Date: 08/ 15/2016 \\n \\nConfidential   1 Abbreviated Title:  AMP-224 SBRT  Met Colorectal Ca   \\nNCI Protocol #:   15-C-0021 B \\nVersion Date:   08/15/2016 \\nTitle: A Pilot Study of AMP-224 – a PD-1 Inhibitor – in Combination with Stereotactic Body \\nRadiation Therapy (SBRT) in Patients with Metastatic Colorectal Cancer  \\n \\nPrincipal Investigator:     Tim Greten, MD A-F \\nThoracic & GI Oncology Branch  \\nNational Cancer Institute   \\nBuilding 10, Room 3B43  \\n9000 Rockville Pike  \\nBethesda, MD 20892 \\n301-451-4723 \\nFAX: 301-480-8780 \\ngretentf@mail.nih.gov  \\nLead Associate Investigator :      Austin Duffy, MDA-F \\nAssociate Investigators :    Deborah Citrin, MD, ROB , CCR, NCIA, B, E  \\nBrad Wood MD, RAD IS, CC, NIHA, B, E \\nWilliam D. Figg, PharmD, GMB , CCR, NCIB, E  \\nSuzanne Fioravanti, RN, OCD, CCR, NCIA,B  \\nMelissa Walker RN, OCD, CCR, NCIA, B  \\nJennifer Jones MD, PhD , VB, CCR, NCIA, B,E \\nSeth Steinberg, PhD , BDMS, OCD, CCR, NCIF \\n \\nReferral Contact/  \\nStudy Coordinator :         Suzanne Fioravanti, RN, OCD , CCR, NCI  \\n 10 Center Drive Room 13N220 \\n Bethesda, MD 20982 \\n Phone: (301) 594-6544 \\n Email: fioravas@mail.nih.gov  \\nRoles of investigators:  \\nA. Obtain information by intervening or interacting with living individuals for research \\npurposes \\nB. Obtaining identifiable private information about living individuals  \\nC. Obtaining the voluntary informed consent of individuals to be subjects  \\nD. Makes decisions about subject eligibility  \\nE. Studying, interpreting, or analyzing identifiable private information or data/specimens \\nfor research purposes  \\nF. Studying, interpreting, or analyzing de -identified data or specimens for research \\npurposes \\nAbbreviated Title: AMP-224 SBRT Met Colorectal Ca   \\nVersion Date: 08/ 15/2016 \\n \\nConfidential   2 Investigational Agents:      \\nDrug Name:  AMP-224 \\nIND Number:  123468 \\nSponsor: Center for Cancer Research, National Cancer Institute  \\nManufacturer:  Amplimmune , Inc. \\n \\n \\n  '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_first_three_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abbreviated Title: AMP-224 SBRT Met Colorectal Ca',\n",
       " 'Confidential   1 Abbreviated Title:  AMP-224 SBRT  Met Colorectal Ca',\n",
       " 'Title: A Pilot Study of AMP-224 – a PD-1 Inhibitor – in Combination with Stereotactic Body ',\n",
       " 'Abbreviated Title: AMP-224 SBRT Met Colorectal Ca']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'role': 'system', 'content': [{'type': 'text', 'text': '-Goal-\\nGiven a snipped of text from a clinical study protocol, a trained medical professional asks a question. Answer the question based on the given context.\\n          \\n-Steps-\\n1. Identify if the context answers the question or not.\\n2. From the context, identify the most relevant portions to the question.\\n3. Based on the context and the identified relevant sections, answer the question. Format your answer in a bullet point list.\\n'}]}, {'role': 'user', 'content': [{'type': 'text', 'text': \"-Context-\\n['Abbreviated', 'Title:', 'AMP-224', 'SBRT', 'Met', 'Colorectal', 'Ca', '', '', '\\\\nVersion', 'Date:', '08/', '15/2016', '\\\\n', '\\\\nConfidential', '', '', '1', 'Abbreviated', 'Title:', '', 'AMP-224', 'SBRT', '', 'Met', 'Colorectal', 'Ca', '', '', '\\\\nNCI', 'Protocol', '#:', '', '', '15-C-0021', 'B', '\\\\nVersion', 'Date:', '', '', '08/15/2016', '\\\\nTitle:', 'A', 'Pilot', 'Study', 'of', 'AMP-224', '–', 'a', 'PD-1', 'Inhibitor', '–', 'in', 'Combination', 'with', 'Stereotactic', 'Body', '\\\\nRadiation', 'Therapy', '(SBRT)', 'in', 'Patients', 'with', 'Metastatic', 'Colorectal', 'Cancer', '', '\\\\n', '\\\\nPrincipal', 'Investigator:', '', '', '', '', 'Tim', 'Greten,', 'MD', 'A-F', '\\\\nThoracic', '&', 'GI', 'Oncology', 'Branch', '', '\\\\nNational', 'Cancer', 'Institute', '', '', '\\\\nBuilding', '10,', 'Room', '3B43', '', '\\\\n9000', 'Rockville', 'Pike', '', '\\\\nBethesda,', 'MD', '20892', '\\\\n301-451-4723', '\\\\nFAX:', '301-480-8780', '\\\\ngretentf@mail.nih.gov', '', '\\\\nLead', 'Associate', 'Investigator', ':', '', '', '', '', '', 'Austin', 'Duffy,', 'MDA-F', '\\\\nAssociate', 'Investigators', ':', '', '', '', 'Deborah', 'Citrin,', 'MD,', 'ROB', ',', 'CCR,', 'NCIA,', 'B,', 'E', '', '\\\\nBrad', 'Wood', 'MD,', 'RAD', 'IS,', 'CC,', 'NIHA,', 'B,', 'E', '\\\\nWilliam', 'D.', 'Figg,', 'PharmD,', 'GMB', ',', 'CCR,', 'NCIB,', 'E', '', '\\\\nSuzanne', 'Fioravanti,', 'RN,', 'OCD,', 'CCR,', 'NCIA,B', '', '\\\\nMelissa', 'Walker', 'RN,', 'OCD,', 'CCR,', 'NCIA,', 'B', '', '\\\\nJennifer', 'Jones', 'MD,', 'PhD', ',', 'VB,', 'CCR,', 'NCIA,', 'B,E', '\\\\nSeth', 'Steinberg,', 'PhD', ',', 'BDMS,', 'OCD,', 'CCR,', 'NCIF', '\\\\n', '\\\\nReferral', 'Contact/', '', '\\\\nStudy', 'Coordinator', ':', '', '', '', '', '', '', '', '', 'Suzanne', 'Fioravanti,', 'RN,', 'OCD', ',', 'CCR,', 'NCI', '', '\\\\n', '10', 'Center', 'Drive', 'Room', '13N220', '\\\\n', 'Bethesda,', 'MD', '20982', '\\\\n', 'Phone:', '(301)', '594-6544', '\\\\n', 'Email:', 'fioravas@mail.nih.gov', '', '\\\\nRoles', 'of', 'investigators:', '', '\\\\nA.', 'Obtain', 'information', 'by', 'intervening', 'or', 'interacting', 'with', 'living', 'individuals', 'for', 'research', '\\\\npurposes', '\\\\nB.', 'Obtaining', 'identifiable', 'private', 'information', 'about', 'living', 'individuals', '', '\\\\nC.', 'Obtaining', 'the', 'voluntary', 'informed', 'consent', 'of', 'individuals', 'to', 'be', 'subjects', '', '\\\\nD.', 'Makes', 'decisions', 'about', 'subject', 'eligibility', '', '\\\\nE.', 'Studying,', 'interpreting,', 'or', 'analyzing', 'identifiable', 'private', 'information', 'or', 'data/specimens', '\\\\nfor', 'research', 'purposes', '', '\\\\nF.', 'Studying,', 'interpreting,', 'or', 'analyzing', 'de', '-identified', 'data', 'or', 'specimens', 'for', 'research', '\\\\npurposes', '\\\\nAbbreviated', 'Title:', 'AMP-224', 'SBRT', 'Met', 'Colorectal', 'Ca', '', '', '\\\\nVersion', 'Date:', '08/', '15/2016', '\\\\n', '\\\\nConfidential', '', '', '2', 'Investigational', 'Agents:', '', '', '', '', '', '\\\\nDrug', 'Name:', '', 'AMP-224', '\\\\nIND', 'Number:', '', '123468', '\\\\nSponsor:', 'Center', 'for', 'Cancer', 'Research,', 'National', 'Cancer', 'Institute', '', '\\\\nManufacturer:', '', 'Amplimmune', ',', 'Inc.', '\\\\n', '\\\\n', '\\\\n', '', '']\\n\\n-Question-\\nWhat is the descriptive title of this study?\"}]}], 'max_tokens': 20}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'choices': [{'content_filter_results': {'hate': {'filtered': False,\n",
       "     'severity': 'safe'},\n",
       "    'self_harm': {'filtered': False, 'severity': 'safe'},\n",
       "    'sexual': {'filtered': False, 'severity': 'safe'},\n",
       "    'violence': {'filtered': False, 'severity': 'safe'}},\n",
       "   'finish_reason': 'length',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'message': {'content': '- The context provides the descriptive title under the \"Title:\" section followed by the details of the study',\n",
       "    'role': 'assistant'}}],\n",
       " 'created': 1722832656,\n",
       " 'id': 'chatcmpl-9sjlQhVbF8dhbs1ksOkLSkXe9eeVX',\n",
       " 'model': 'gpt-4-turbo-2024-04-09',\n",
       " 'object': 'chat.completion',\n",
       " 'prompt_filter_results': [{'prompt_index': 0,\n",
       "   'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'},\n",
       "    'self_harm': {'filtered': False, 'severity': 'safe'},\n",
       "    'sexual': {'filtered': False, 'severity': 'safe'},\n",
       "    'violence': {'filtered': False, 'severity': 'safe'}}}],\n",
       " 'system_fingerprint': 'fp_811936bd4f',\n",
       " 'usage': {'completion_tokens': 20,\n",
       "  'prompt_tokens': 1249,\n",
       "  'total_tokens': 1269}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_first_three_pages = \"\\n\".join([p.extract_text() for p in reader.pages[:2]])\n",
    "message = f\"\"\"-Context-\n",
    "{text_first_three_pages.split(' ')}\n",
    "\n",
    "-Question-\n",
    "What is the full title of this study?\"\"\"\n",
    "response = llm_model.invoke(message)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval - Semantic Similarity\n",
    "\n",
    "Calculate semantic similarity of the categories (purpose, procedures, risks, benefits) against the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/bterr/Projects/artos_icf_generation/.direnv/python-3.11.9/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/mnt/c/Users/bterr/Projects/artos_icf_generation/.direnv/python-3.11.9/lib/python3.11/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "categories = [\"purpose\", \"procedures\", \"risks\", \"benefits\"]\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "category_embeddings = model.encode(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalization(features: torch.tensor):\n",
    "    feature_max = features.max()\n",
    "    feature_min = features.min()\n",
    "    return (features - feature_min) / (feature_max - feature_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval - Semantic Similarity - Topic Outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 181])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_embeddings = model.encode([str(key) for key in title_segment_lookup.keys()])\n",
    "topic_similarities = model.similarity(category_embeddings, topic_embeddings)\n",
    "topic_similarities.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval - Semantic Similarity - Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 930])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings = model.encode(pdf_sentences)\n",
    "sentence_similarity = model.similarity(category_embeddings, sentence_embeddings)\n",
    "sentence_similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purpose tensor(3) 1 INTRODUCTION\n",
      "purpose tensor(1) SCHEMA\n",
      "purpose tensor(6) 1.1.2 Secondary Objectives\n",
      "purpose tensor(177) 12 REFERENCES\n",
      "purpose tensor(4) 1.1 Study Objectives\n",
      "purpose tensor(0) PRÉCIS\n",
      "purpose tensor(157) 10.3 Evaluation of Benefits and Risks/Discomforts\n",
      "purpose tensor(156) 10.2 Participation of Children\n",
      "purpose tensor(155) 10.1 Rationale For Subject Selection\n",
      "purpose tensor(154) 10 HUMAN SUBJECTS PROTECTIONS\n"
     ]
    }
   ],
   "source": [
    "titles = [t.title for t in title_segment_lookup.values()]\n",
    "for i in topic_similarities[0].argsort(descending=True)[:10]:\n",
    "    print(categories[0], i, titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "procedures The procedure for protecting against or minimizing risks will be to medically evaluate patients on a regular basis as described.\n",
      "procedures During that meeting, the investigator will inform patients of the purpose, alternatives, treatment plan, research objectives and follow -up of this trial.\n",
      "procedures For each sample, there are notes associated with the processing method (delay in sample processing, storage conditions on the ward, etc.).\n",
      "procedures A preliminary report from a phase 2 trial.\n",
      "procedures It is the responsibility of the NCI Principal Investigator to ensure that the samples requested are being used in a manner consistent with IRB approval.\n",
      "procedures All specimens obtained in the protocol are used as defined in the protocol.\n",
      "procedures The investigator will then provide a copy of t he IRB-approved informed consent document that is included in this protocol.\n",
      "procedures The informed consent pr ocess will be documented on a progress note by the consenting  investigator and a copy of the informed consent document and note will be kept in the subject’s research record.\n",
      "procedures The principal investigator will personally conduct or supervise the investigation and provide appropriate delegation of responsibilities to other members of the research staff.\n",
      "procedures Results must be reviewed prior to infusion.\n"
     ]
    }
   ],
   "source": [
    "for i in sentence_similarity[1].argsort(descending=True)[:10]:\n",
    "    print(categories[1], pdf_sentences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation - Generate Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_MAX = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a custom azure openai module for simpler control than langchain\n",
    "from llm import LLM\n",
    "\n",
    "prompt = \"\"\"-Goal-\n",
    "Given a snipped of text from a clinical study protocol, a trained medical professional asks a question. Answer the question based on the given context.\n",
    "          \n",
    "-Steps-\n",
    "1. Identify if the context answers the question or not.\n",
    "2. From the context, identify the most relevant portions to the question.\n",
    "3. Based on the context and the identified relevant sections, answer the question. Format your answer in a bullet point list.\n",
    "\"\"\"\n",
    "llm_model = LLM(prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation - Study Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try against sentence based embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the purpose of the clinical trial study?\"\n",
    "available_prompt_space = TOKEN_MAX - len(prompt.split(\" \")) - len(question.split(\" \")) - 200\n",
    "\n",
    "current_index = 0\n",
    "sentence_similarities_rankings = sentence_similarity[0].argsort(descending=True)\n",
    "context = \"\"\n",
    "\n",
    "while available_prompt_space > 0:\n",
    "    sentence_index = sentence_similarities_rankings[current_index]\n",
    "    current_sentence = pdf_sentences[sentence_index]\n",
    "\n",
    "    if available_prompt_space - len(current_sentence) > 0:\n",
    "        available_prompt_space -= len(current_sentence)\n",
    "        context += current_sentence\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'role': 'system', 'content': [{'type': 'text', 'text': '-Goal-\\nGiven a snipped of text from a clinical study protocol, a trained medical professional asks a question. Answer the question based on the given context.\\n          \\n-Steps-\\n1. Identify if the context answers the question or not.\\n2. From the context, identify the most relevant portions to the question.\\n3. Based on the context and the identified relevant sections, answer the question. Format your answer in a bullet point list.\\n'}]}, {'role': 'user', 'content': [{'type': 'text', 'text': '\\n-Context-\\nDuring that meeting, the investigator will inform patients of the purpose, alternatives, treatment plan, research objectives and follow -up of this trial.\\n\\n-Question-\\nWhat is the purpose of this study?'}]}], 'max_tokens': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'choices': [{'content_filter_results': {'hate': {'filtered': False,\n",
       "     'severity': 'safe'},\n",
       "    'self_harm': {'filtered': False, 'severity': 'safe'},\n",
       "    'sexual': {'filtered': False, 'severity': 'safe'},\n",
       "    'violence': {'filtered': False, 'severity': 'safe'}},\n",
       "   'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'message': {'content': '- The context does not provide specific details about the purpose of the study.\\n- The context mentions that during the meeting, the investigator will inform patients about the purpose of the trial, but it does not specify what the purpose is.',\n",
       "    'role': 'assistant'}}],\n",
       " 'created': 1722832194,\n",
       " 'id': 'chatcmpl-9sjdy1ZxZhdBo8eX1C4QG4Z9tSy15',\n",
       " 'model': 'gpt-4-turbo-2024-04-09',\n",
       " 'object': 'chat.completion',\n",
       " 'prompt_filter_results': [{'prompt_index': 0,\n",
       "   'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'},\n",
       "    'self_harm': {'filtered': False, 'severity': 'safe'},\n",
       "    'sexual': {'filtered': False, 'severity': 'safe'},\n",
       "    'violence': {'filtered': False, 'severity': 'safe'}}}],\n",
       " 'system_fingerprint': 'fp_811936bd4f',\n",
       " 'usage': {'completion_tokens': 46, 'prompt_tokens': 142, 'total_tokens': 188}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm_model.invoke(f\"\"\"\n",
    "-Context-\n",
    "{context}\n",
    "\n",
    "-Question-\n",
    "{question}\"\"\", max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 384)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = [\n",
    "    \"A Nurse-led Family-oriented Resilience Program for Caregivers of Community-dwelling Dependent Older Adults\",\n",
    "    \"Artificial Intelligence Assisted Breast Ultrasound in Breast Cancer Screening\",\n",
    "    \"Active Cycle Breathing Technique (ACBT) on Respiratory Function Forced Expiration Technique (FET)\",\n",
    "    \"Novel Locator-Positioner Device for Temporomandibular Joint Arthroscopy\",\n",
    "    \"Comparison Between Continuous and Pulsed Oral Doxycycline Treatment Protocols for Refractory Meibomian Gland Dysfunction\",\n",
    "    \"Integrated Genetic and Functional Analysis of the Influence of Menstrual Hygiene Products on Female Health\",\n",
    "    \"Liver-gut Axis Study Through Identification of Liver Disease-specific Microbiome\",\n",
    "    \"Treatment With Psilocybin for Chronic Neuropathic Pain and Depression (TRANSCEND)\",\n",
    "    \"Investigating the Influence of Catheter Advancement Techniques on Needle Tip Movement During Intravenous Insertion\",\n",
    "    \"Efficacy and Safety of Different Hyaluronic Acid Tear Substitutes Formulations in Evaporative Dry Eye\",\n",
    "]\n",
    "title_embedding = model.encode(titles)\n",
    "title_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(title_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "centroid = np.median(title_embedding, axis=0)\n",
    "centroid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"title_centroid.bytes\", \"wb\") as f:\n",
    "    f.write(centroid.tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 1, 0, 8, 7, 9, 3, 2, 5, 4]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(i) for i in model.similarity(centroid, title_embedding).flatten().argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deserialized_bytes = np.frombuffer(centroid.tobytes(), dtype=np.float32)\n",
    "deserialized_bytes == centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
